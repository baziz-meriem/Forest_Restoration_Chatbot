{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Llama 2: Leveraging the META Language Model on HuggingFace\n","\n","Explore the capabilities of the META LLM (Language Model) and its integration with HuggingFace for innovative natural language processing tasks and applications. Join us in harnessing the power of cutting-edge AI for text generation and understanding."],"metadata":{"id":"8nR9tIpf13pe"}},{"cell_type":"markdown","source":["# Streamlit"],"metadata":{"id":"WldY0d6wXNkt"}},{"cell_type":"code","source":["!pip install streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVHuWXKvXSDp","outputId":"be95636a-d975-4b24-cc3a-e85efe6e7f0e","executionInfo":{"status":"ok","timestamp":1697371763715,"user_tz":-330,"elapsed":7027,"user":{"displayName":"mohammad maaz","userId":"17271946119795207204"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.27.2-py2.py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n","Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n","Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n","Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n","Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n","Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n","Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.6.0)\n","Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n","Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.1)\n","Collecting validators<1,>=0.2 (from streamlit)\n","  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n","Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n","  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n","Collecting watchdog>=2.1.5 (from streamlit)\n","  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.4)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n","Successfully installed gitdb-4.0.10 gitpython-3.1.37 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.27.2 validators-0.22.0 watchdog-3.0.0\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import subprocess\n","\n","# Install required packages\n","subprocess.run([\"pip\", \"install\", \"-qU\", \"transformers\", \"accelerate\", \"einops\", \"langchain\", \"xformers\", \"bitsandbytes\", \"faiss-gpu\", \"sentence_transformers\", \"torch\"])\n","import torch\n","from torch import cuda\n","import transformers\n","from transformers import StoppingCriteria, StoppingCriteriaList\n","from langchain.callbacks.manager import CallbackManager\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from transformers import pipeline, TextStreamer\n","import accelerate\n","\n","model_id = 'meta-llama/Llama-2-13b-chat-hf'\n","\n","device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n","\n","# set quantization configuration to load large model with less GPU memory\n","# this requires the `bitsandbytes` library\n","\n","\n","\n","device_map = {\n","\"transformer.word_embeddings\": \"cuda\",\n","\"transformer.word_embeddings_layernorm\": \"cuda\",\n","\"lm_head\": \"cuda\",\n","\"transformer.h\": \"cuda\",\n","\"transformer.ln_f\": \"cuda\",\n","\"model.embed_tokens\": \"cpu\",\n","\"model.layers\":\"cpu\",\n","\"model.norm\":\"cpu\"\n","}\n","\n","# begin initializing HF items, you need an access token\n","hf_auth = \"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\" #'<add your access token here>'\n","#create a model configuration object\n","\n","model_config = transformers.AutoConfig.from_pretrained(\n","    model_id,\n","    use_auth_token=hf_auth\n",")\n","model = transformers.AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    trust_remote_code=True,\n","    config=model_config,\n","    device_map=device_map,\n","    use_auth_token=hf_auth\n",")\n","\n","# enable evaluation mode to allow model inference (not update the weights)\n","model.eval()\n","\n","print(f\"Model loaded on {device}\")\n","#creates the adequate tokenizer automatically\n","tokenizer = transformers.AutoTokenizer.from_pretrained(\n","    model_id,\n","    use_auth_token=hf_auth\n",")\n","\n","\n","\n","\n","\n","stop_list = ['\\nHuman:', '\\n```\\n']\n","\n","stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n","tokenizer('\\nHuman:') #attention mask helps determine the importatn tokens from the just padding tokens\n","\n","stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n","\n","\n","# define custom stopping criteria object\n","class StopOnTokens(StoppingCriteria):\n","    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n","        for stop_ids in stop_token_ids:\n","            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():#to compare the ending part of the generated sequence with stop_ids  torch.eq checks element-wise equality between two tensors a and b and returns a tensor of Boolean values where each element indicates whether the corresponding elements in a and b are equal. all checks if all element of the tensor are ==1\n","                return True\n","        return False\n","#init list with one stopping criterion\n","stopping_criteria = StoppingCriteriaList([StopOnTokens()])\n","\n","\n","# Callbacks support token-wise streaming\n","callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n","# Verbose is required to pass to the callback manager\n","\n","\n","\n","# Show word by word in the screen\n","streamer = TextStreamer(tokenizer,\n","                        skip_prompt=True) #skip or ignore any prompts that may be present in the text data\n","\n","generate_text = transformers.pipeline(\n","    model=model,\n","    tokenizer=tokenizer,\n","    return_full_text=True,  # langchain expects the full text\n","    task='text-generation',\n","    # we pass model parameters here too\n","    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n","    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n","    max_new_tokens=512,  # max number of tokens to generate in the output\n","    repetition_penalty=1.1,  # without this output begins repeating\n","    do_sample=True,\n","    top_k=10,\n","    num_return_sequences=1,\n","    streamer=streamer,\n","    eos_token_id=tokenizer.eos_token_id\n",")\n","\n","import streamlit as st\n","\n","\n","st.title('🦜🔗 Quickstart App')\n","\n","openai_api_key = st.sidebar.text_input('OpenAI API Key')\n","\n","def generate_response(input_text):\n","  res = generate_text(input_text)\n","  st.info(res[0])\n","\n","with st.form('my_form'):\n","  text = st.text_area('Enter text:', 'What are the three key pieces of advice for learning how to code?')\n","  submitted = st.form_submit_button('Submit')\n","  generate_response(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQiAqb2ziN7X","outputId":"90802537-9b35-4c8c-a8e2-ca00395b15d9","executionInfo":{"status":"ok","timestamp":1697371770308,"user_tz":-330,"elapsed":12,"user":{"displayName":"mohammad maaz","userId":"17271946119795207204"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","source":["!streamlit run app.py & npx localtunnel --port 8501"],"metadata":{"id":"cUl8NiAoXSQh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0baeaf49-20ad-415d-9e8e-cd964a56d3e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[..................] / rollbackFailedOptional: verb npm-session 5c3df7cc7235226\u001b[0m\u001b[K\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.32.219.140:8501\u001b[0m\n","\u001b[0m\n","\u001b[K\u001b[?25hnpx: installed 22 in 4.214s\n","your url is: https://angry-nails-bow.loca.lt\n"]}]},{"cell_type":"code","source":["#get the IP address where the app  is running\n","!wget -q -O - ipv4.icanhazip.com"],"metadata":{"id":"mZr41qdsXSVs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"58196806-54c4-4059-9ec5-023b6845a66a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["35.229.55.224\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KIpPGYGyXSbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9x7QuN_MXSsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7d0R4zy9XSuf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bYZO02gdXSyb"},"execution_count":null,"outputs":[]}]}